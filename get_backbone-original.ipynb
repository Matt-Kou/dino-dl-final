{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "import torch\n",
    "import os\n",
    "import torchvision.models.resnet as resnet\n",
    "from typing import Type, Any, Callable, Union, List, Optional\n",
    "import torch.nn as nn\n",
    "from torch import Tensor"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "DEVICE = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "pretrained_weights = os.path.join(os.getcwd(), 'inputs', 'resnet.pth')\n",
    "checkpoint_key = 'teacher'\n",
    "patch_size = 8"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "class ResnetBackbone(resnet.ResNet):\n",
    "    def __init__(\n",
    "            self,\n",
    "            block: Type[Union[resnet.BasicBlock, resnet.Bottleneck]],\n",
    "            layers: List[int],\n",
    "            num_classes: int = 1000,\n",
    "            zero_init_residual: bool = False,\n",
    "            groups: int = 1,\n",
    "            width_per_group: int = 64,\n",
    "            replace_stride_with_dilation: Optional[List[bool]] = None,\n",
    "            norm_layer: Optional[Callable[..., nn.Module]] = None,\n",
    "    ) -> None:\n",
    "        resnet.ResNet.__init__(self, block, layers, num_classes, zero_init_residual, groups, width_per_group,\n",
    "                               replace_stride_with_dilation, norm_layer)\n",
    "        self.num_channels = 2048\n",
    "\n",
    "    def _forward_impl(self, x: Tensor) -> Tensor:\n",
    "        # See note [TorchScript super()]\n",
    "        x = self.conv1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.maxpool(x)\n",
    "\n",
    "        x = self.layer1(x)\n",
    "        x = self.layer2(x)\n",
    "        x = self.layer3(x)\n",
    "        x = self.layer4(x)\n",
    "        return x\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "def resnet50(pretrained: bool = False, progress: bool = True, **kwargs: Any) -> ResnetBackbone:\n",
    "    return _resnet(\"resnet50\", resnet.Bottleneck, [3, 4, 6, 3], pretrained, progress, **kwargs)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "def _resnet(\n",
    "    arch: str,\n",
    "    block: Type[Union[resnet.BasicBlock, resnet.Bottleneck]],\n",
    "    layers: List[int],\n",
    "    pretrained: bool,\n",
    "    progress: bool,\n",
    "    **kwargs: Any,\n",
    ") -> ResnetBackbone:\n",
    "    model = ResnetBackbone(block, layers, **kwargs)\n",
    "    return model"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Take key teacher in provided checkpoint dict\n",
      "Pretrained weights found at C:\\Users\\YifengKou\\OneDrive - nyu.edu\\Desktop\\dino\\inputs\\resnet.pth and loaded with msg: _IncompatibleKeys(missing_keys=['fc.weight', 'fc.bias'], unexpected_keys=['head.mlp.0.weight', 'head.mlp.0.bias', 'head.mlp.2.weight', 'head.mlp.2.bias', 'head.mlp.4.weight', 'head.mlp.4.bias', 'head.last_layer.weight_g', 'head.last_layer.weight_v'])\n"
     ]
    }
   ],
   "source": [
    "backbone = resnet50()\n",
    "backbone.to(DEVICE)\n",
    "if os.path.isfile(pretrained_weights):\n",
    "    state_dict = torch.load(pretrained_weights, map_location=\"cpu\")\n",
    "    if (\n",
    "        checkpoint_key is not None\n",
    "        and checkpoint_key in state_dict\n",
    "    ):\n",
    "        print(\n",
    "            f\"Take key {checkpoint_key} in provided checkpoint dict\"\n",
    "        )\n",
    "        state_dict = state_dict[checkpoint_key]\n",
    "\n",
    "\n",
    "    state_dict = {k.replace(\"module.\", \"\"): v for k, v in state_dict.items()}\n",
    "    # remove `backbone.` prefix induced by multicrop wrapper\n",
    "    state_dict = {k.replace(\"backbone.\", \"\"): v for k, v in state_dict.items()}\n",
    "    msg = backbone.load_state_dict(state_dict, strict=False)\n",
    "    print(\n",
    "        \"Pretrained weights found at {} and loaded with msg: {}\".format(\n",
    "            pretrained_weights, msg\n",
    "        )\n",
    "    )\n",
    "else:\n",
    "    print(\"error!!!!!!!!!!!!!!\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "torch.save(backbone.state_dict(), os.path.join(\"zoo\", \"resnet-full-nofc.pth\"))\n",
    "torch.save(backbone, os.path.join(\"zoo\", \"resnet-full-nofc\"))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}